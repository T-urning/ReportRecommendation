{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 报告数据标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481 {'date': '2021-10-16 星期六', 'hall': '黄龙水晶宫', 'host': '陆锋', 'topic': '09:10-10:40 | 特邀报告', 'time': '09:10-09:40', 'title': '全球位置服务网关键技术与研究进展', 'reporters': '龚健雅 院士', 'institutions': '武汉大学'} {'分会场十三', '分会场四', '分会场九', '分会场十一', '分会场八', '分会场十', '分会场三', '分会场五', '分会场六', '分会场二', '分会场十四', '分会场十二', '分会场七', '黄龙水晶宫', '分会场一'}\n",
      "{'分会场一': 0, '分会场七': 1, '分会场三': 2, '分会场九': 3, '分会场二': 4, '分会场五': 5, '分会场八': 6, '分会场六': 7, '分会场十': 8, '分会场十一': 9, '分会场十三': 10, '分会场十二': 11, '分会场十四': 12, '分会场四': 13, '黄龙水晶宫': 14}\n"
     ]
    }
   ],
   "source": [
    "data = json.load(open('data/conference/conference.json', encoding='utf-8', mode='r'))\n",
    "reports = []\n",
    "halls = set()\n",
    "for report in data:\n",
    "    title = report['title']\n",
    "    institutions = report['institutions']\n",
    "    if title and institutions:\n",
    "        reports.append(report)\n",
    "        halls.add(report['hall'])\n",
    "\n",
    "hall_2_id = {h:i for i, h in enumerate(sorted(halls))}\n",
    "id_2_hall = {i:h for h, i in hall_2_id.items()}\n",
    "print(len(reports), reports[0], halls)\n",
    "print(hall_2_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 报告时间与会场标准化\n",
    "需要提一下，有重复报告，这里我们采用去重的方法解决"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "康巴藏区藏传佛教寺院的空间布局特征及其影响因素\n",
      "基于GPS轨迹的西藏骑行游客时空行为分析\n",
      "基于轨迹大数据的游客行为研究：总结、局限与展望\n",
      "{'date': '2021-10-16', 'hall': '黄龙水晶宫', 'host': '陆锋', 'topic': '特邀报告', 'time': '09:10-09:40', 'title': '全球位置服务网关键技术与研究进展', 'reporters': '龚健雅 院士', 'institutions': '武汉大学', 'start_time': 119400, 'end_time': 121200, 'hall_id': 14, 'time_group': 0, 'id': 0}\n",
      "478 481\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "time_format = '%Y-%m-%d %H:%M'\n",
    "base_time = datetime(2021, 10, 15)\n",
    "new_data = []\n",
    "start_time_set = set()\n",
    "title_set = set()\n",
    "for report in reports:\n",
    "    title = report['title']\n",
    "    if title in title_set: \n",
    "        print(title)\n",
    "        continue\n",
    "    title_set.add(title)\n",
    "    date = report['date']\n",
    "    time = report['time']\n",
    "    hall = report['hall']\n",
    "    topic = report['topic']\n",
    "    topic = topic.split('|')[-1].split('：')[-1].strip()\n",
    "    date = date.split(' ')[0]\n",
    "    start, end = time.split('-')\n",
    "    start_time = date + ' ' + start # datetime.strptime(date + ' ' + start, time_format)\n",
    "    end_time = date + ' ' + end\n",
    "    s_time = datetime.strptime(start_time, time_format) - base_time\n",
    "    e_time = datetime.strptime(end_time, time_format) -  base_time\n",
    "    hall_id = hall_2_id[hall]\n",
    "    report['date'] = date\n",
    "    report['start_time'] = int(s_time.total_seconds())\n",
    "    report['end_time'] = int(e_time.total_seconds())\n",
    "    report['hall_id'] = hall_id\n",
    "    report['topic'] = topic\n",
    "    start_time_set.add(start_time)\n",
    "    new_data.append(report)\n",
    "json.dump(new_data, open('data/conference/standard_conference_data.json', 'w', encoding='utf-8'), ensure_ascii=False)\n",
    "print(new_data[0])\n",
    "print(len(title_set), len(reports))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 按时间段分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "min_delta = 600\n",
    "time_spans = []\n",
    "sorted_data = sorted(new_data, key=lambda x: x['start_time']) # 按开始时间排序\n",
    "t = sorted_data[0]['start_time']\n",
    "group = 0\n",
    "group_dict = defaultdict(lambda: list())\n",
    "# group_dict[group] = []\n",
    "topic_2_reports = defaultdict(lambda: list())\n",
    "for i, report in enumerate(sorted_data):\n",
    "    s_time = int(report['start_time'])\n",
    "    e_time = int(report['end_time'])\n",
    "    topic = report['topic']\n",
    "    delta = s_time - t\n",
    "\n",
    "    if delta > min_delta:\n",
    "        group += 1\n",
    "        t = s_time\n",
    "    group_dict[group].append(i)   \n",
    "    report['time_group'] = group\n",
    "    report['id'] = i\n",
    "    topic_2_reports[topic].append((i, report['title']))\n",
    "print(group)\n",
    "json.dump(sorted_data, open(f'data/conference/grouped_conference_data_{min_delta}.json', 'w', encoding='utf-8'), ensure_ascii=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最长组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "group_max_len = max([len(g) for k, g in group_dict.items()])\n",
    "print(group_max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_keywords = ['时空大数据', '人工智能', '粤港澳大湾区', '空间可达性', '光学遥感',  \n",
    "                    '轨迹数据挖掘', '时空模拟与预测', '地理时空建模', '遥感变化检测与地图更新', '地理信息共享与互操作'] # 五个抽取的关键词，五个专题名\n",
    "with open('data/text_match/predict.jl', 'w', encoding='utf-8') as writer:\n",
    "    for keyword in testing_keywords:\n",
    "        for report in sorted_data:\n",
    "            writer.write(json.dumps({'title': report['title'], 'keywords': [keyword]}, ensure_ascii=False))\n",
    "            writer.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_matrix = np.zeros((len(sorted_data), len(testing_keywords)), dtype=float)\n",
    "with open('outputs/text_match/predictions/bert_bert_wwm_ext_2_prediction_text_matching.jl', 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        d_json = json.loads(line.strip())\n",
    "        prob = float(d_json['prob'])\n",
    "        col = i // len(sorted_data)\n",
    "        row = i - col * len(sorted_data)\n",
    "        prob_matrix[row, col] = prob\n",
    "    assert i == len(sorted_data) * len(testing_keywords) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 查看与关键词最匹配的标题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "地理信息共享与互操作 :\n",
      "地理信息共享新模式：从分析就绪、AI就绪到决策就绪 12.150110244750977\n",
      "地理分析模型的共享与重用方法研究 4.1197638511657715\n",
      "支持地理信息服务链可视化构建与执行的BPMN扩展框架模型设计 3.643040657043457\n",
      "地理空间模型数据自动匹配研究：地理空间数据—模型共享的新范式（线上） 3.2376365661621094\n",
      "智慧城市背景下的地理信息知识组织与重用 3.184375762939453\n",
      "NSFC信息地理学的机遇与挑战 3.0859227180480957\n",
      "一种顾及QoS的地理信息服务关系网络模型 2.878934621810913\n",
      "一种多元地理信息处理服务拓展的框架构建 2.776102304458618\n",
      "不同可持续发展目标情景下地理智能建模 2.673800468444824\n",
      "地理大数据挖掘的方法体系及主要进展 2.5489742755889893\n",
      "地图语言的延伸与多模态地理信息融合表达 2.5290110111236572\n",
      "多源空间信息同化与共享服务关键技术研究 2.485527753829956\n",
      "一种互信息领域自适应网络用于高分辨率语义分割 2.378546953201294\n",
      "从地理空间到神经空间：类脑导航研究进展 2.3710427284240723\n",
      "地理时空认知与医学内镜手术 2.3696205615997314\n",
      "地理认知与GIS创新 2.3609416484832764\n",
      "地理大数据支持下的人群动态多尺度制图方法研究 2.2649688720703125\n",
      "WebGL技术在虚拟地理环境构建中的应用研究 2.1219546794891357\n",
      "利用地理大数据刻画空间交互模式 1.9393177032470703\n",
      "自然与人为过程耦合的地理模拟平台搭建及应用 1.7854048013687134\n",
      "Urban Expansion and Drying Climate in Urban Agglomerations of China 1.7411761283874512\n",
      "明清江南市镇体系演化的若干地理特征 1.7225759029388428\n",
      "Beyond absolute space: An exploration of relative and relational space in Shanghai using taxi trajectory data 1.7108941078186035\n",
      "基于大数据的旅游情感地理探索 1.7038577795028687\n",
      "Potential and limitations of interpretable machine learning algorithms to predict rare and complex events in space and time 1.6871331930160522\n",
      "Seasonal Forecast of Non-monsoonal Winter Precipitation over the Eurasian Continent using Machine Learning Models 1.6744064092636108\n",
      "虚拟自然地理实验探索-以洪水灾害模拟为例 1.6706068515777588\n",
      "Efficient Soil Moisture mapping based on Apache Spark in IoT environment 1.663559913635254\n",
      "A practical atmospheric correction algorithm for inland and nearshore coastal waters 1.6604089736938477\n",
      "Climate change or human activities dominate farmland loss in divergent ecogeographical regions on the Tibetan Plateau（线上） 1.6454576253890991\n",
      "gold reports:\n",
      "介绍专题设置和特邀报告人\n",
      "知识图谱及其生产平台（线上）\n",
      "对地观测科学数据治理与前沿探索（线上）\n",
      "地理空间模型数据自动匹配研究：地理空间数据—模型共享的新范式（线上）\n",
      "地理分析模型的共享与重用方法研究\n",
      "大数据时空化的基本问题与挑战\n",
      "深时数字地球科学数据共享策略\n",
      "地理信息共享新模式：从分析就绪、AI就绪到决策就绪\n",
      "基于最小描述长度准则与随机合并策略的地图检索意图识别\n"
     ]
    }
   ],
   "source": [
    "ith = 9\n",
    "keyword = testing_keywords[ith]\n",
    "probs = prob_matrix[:, ith]\n",
    "ranks = np.argsort(-probs) # 由于默认使用升序，所以使用负号\n",
    "print(keyword, ':')\n",
    "for i, r in enumerate(ranks[:30]): # 看前十个\n",
    "    report = sorted_data[r]\n",
    "    print(report['title'], probs[r])\n",
    "\n",
    "print('gold reports:')\n",
    "gold_reports = topic_2_reports.get(keyword, [])\n",
    "for i, report in gold_reports:\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概率转移矩阵中参数的确定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 空间距离因素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. 10.  2. 10.  2. 10. 10. 10. 15. 15. 15. 15. 15.  2.  2.]\n",
      " [10.  1. 10.  3. 10.  3.  3.  3. 20. 20. 20. 20. 20. 10. 10.]\n",
      " [ 2. 10.  1. 10.  2. 10. 10. 10. 15. 15. 15. 15. 15.  2.  2.]\n",
      " [10.  3. 10.  1. 10.  3.  3.  3. 20. 20. 20. 20. 20. 10. 10.]\n",
      " [ 2. 10.  2. 10.  1. 10. 10. 10. 15. 15. 15. 15. 15.  2.  2.]\n",
      " [10.  3. 10.  3. 10.  1.  3.  3. 20. 20. 20. 20. 20. 10. 10.]\n",
      " [10.  3. 10.  3. 10.  3.  1.  3. 20. 20. 20. 20. 20. 10. 10.]\n",
      " [10.  3. 10.  3. 10.  3.  3.  1. 20. 20. 20. 20. 20. 10. 10.]\n",
      " [15. 20. 15. 20. 15. 20. 20. 20.  1.  3.  3.  3.  3. 15. 15.]\n",
      " [15. 20. 15. 20. 15. 20. 20. 20.  3.  1.  3.  3.  3. 15. 15.]\n",
      " [15. 20. 15. 20. 15. 20. 20. 20.  3.  3.  1.  3.  3. 15. 15.]\n",
      " [15. 20. 15. 20. 15. 20. 20. 20.  3.  3.  3.  1.  3. 15. 15.]\n",
      " [15. 20. 15. 20. 15. 20. 20. 20.  3.  3.  3.  3.  1. 15. 15.]\n",
      " [ 2. 10.  2. 10.  2. 10. 10. 10. 15. 15. 15. 15. 15.  1.  2.]\n",
      " [ 2. 10.  2. 10.  2. 10. 10. 10. 15. 15. 15. 15. 15.  2.  1.]]\n"
     ]
    }
   ],
   "source": [
    "area1 = {'分会场一', '分会场二', '分会场三', '分会场四', '黄龙水晶宫'}\n",
    "area2 = {'分会场五', '分会场六', '分会场七', '分会场八', '分会场九'}\n",
    "area3 = {'分会场十', '分会场十一', '分会场十二', '分会场十三', '分会场十四'}\n",
    "distance_dict = {\n",
    "    '11': 2, '22': 3, '33': 3,\n",
    "    '12': 10, '21': 10, '13': 15, '31':15,\n",
    "    '23': 20, '32': 20\n",
    "}\n",
    "distance_matrix = np.zeros((len(hall_2_id), len(hall_2_id)), dtype=float)\n",
    "hall_2_area = {h: 1 for h in area1}\n",
    "hall_2_area.update({h: 2 for h in area2})\n",
    "hall_2_area.update({h: 3 for h in area3})\n",
    "\n",
    "for i in range(len(hall_2_id)):\n",
    "    from_hall = id_2_hall[i]\n",
    "    from_area = hall_2_area[from_hall]\n",
    "    distance_matrix[i, i] = 1\n",
    "    for j in range(i):\n",
    "        to_hall = id_2_hall[j]\n",
    "        to_area = hall_2_area[to_hall]\n",
    "        dis = distance_dict[str(from_area)+str(to_area)]\n",
    "        distance_matrix[i, j] = distance_matrix[j, i] = dis\n",
    "print(distance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 时间间隔因素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(start_time_set)\n",
    "transfer_matrices = []\n",
    "for i in range(len(group_dict)-1):\n",
    "    transfer_mat = np.zeros((group_max_len, group_max_len), dtype=float)\n",
    "    from_group = group_dict[i]\n",
    "    to_group = group_dict[i+1]\n",
    "    for i, from_r in enumerate(from_group):\n",
    "        from_hall_id = sorted_data[from_r]['hall_id']\n",
    "        for j, to_r in enumerate(to_group):\n",
    "            to_hall_id = sorted_data[to_r]['hall_id']\n",
    "            distance = distance_matrix[from_hall_id, to_hall_id]\n",
    "            transfer_mat[i, j] = 1 / distance # 距离的倒数\n",
    "    transfer_matrices.append(transfer_mat)\n",
    "print(transfer_matrices[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transfer_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 条件随机场"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "def step(mu_prev: np.ndarray,\n",
    "         emission_probs: np.ndarray,\n",
    "         transition_probs: np.ndarray,\n",
    "         observed_state: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Runs one step of the Viterbi algorithm.\n",
    "    \n",
    "    Args:\n",
    "        mu_prev: probability distribution with shape (num_hidden),\n",
    "            the previous mu\n",
    "        emission_probs: the emission probability matrix (num_hidden,\n",
    "            num_observed)\n",
    "        transition_probs: the transition probability matrix, with\n",
    "            shape (num_hidden, num_hidden)\n",
    "        observed_state: the observed state at the current step\n",
    "    \n",
    "    Returns:\n",
    "        - the mu for the next step\n",
    "        - the maximizing previous state, before the current state,\n",
    "          as an int array with shape (num_hidden)\n",
    "    \"\"\"\n",
    "    \n",
    "    pre_max = mu_prev * transition_probs.T\n",
    "    max_prev_states = np.argmax(pre_max, axis=1)\n",
    "    max_vals = pre_max[np.arange(len(max_prev_states)), max_prev_states]\n",
    "    mu_new = max_vals * emission_probs[:, observed_state]\n",
    "    \n",
    "    return mu_new, max_prev_states\n",
    "\n",
    "\n",
    "def viterbi(emission_probs: np.ndarray,\n",
    "            transition_probs: np.ndarray) -> Tuple[List[int], float]:\n",
    "    \"\"\"Runs the Viterbi algorithm to get the most likely state sequence.\n",
    "    \n",
    "    Args:\n",
    "        emission_probs: the emission probability matrix (num_hidden,\n",
    "            steps)\n",
    "        transition_probs: the transition probability matrix, with\n",
    "            shape (steps-1, num_hidden, num_hidden)\n",
    "    \n",
    "    Returns:\n",
    "        - the most likely series of states\n",
    "        - the joint probability of that series of states and the observed\n",
    "    \"\"\"\n",
    "    \n",
    "    # Runs the forward pass, storing the most likely previous state.\n",
    "    assert emission_probs.shape[-1] - 1 == transition_probs.shape[0]\n",
    "    mu = emission_probs[:, 0]\n",
    "    all_prev_states = []\n",
    "    for t in range(1, emission_probs.shape[-1]):\n",
    "        mu, prevs = step(mu, emission_probs, transition_probs[t-1], t)\n",
    "        all_prev_states.append(prevs)\n",
    "    \n",
    "    # Traces backwards to get the maximum likelihood sequence.\n",
    "    state = np.argmax(mu)\n",
    "    sequence_prob = mu[state]\n",
    "    state_sequence = [state]\n",
    "    for prev_states in all_prev_states[::-1]:\n",
    "        state = prev_states[state]\n",
    "        state_sequence.append(state)\n",
    "    \n",
    "    return state_sequence[::-1], sequence_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 3, 6, 5, 1, 7, 7, 7, 13, 12, 1, 0, 6, 0, 11, 10, 6, 10, 11, 3, 3, 7, 13, 5, 6, 6, 4, 12, 0, 6, 0, 0, 0, 0, 0, 0] 0.0003594295808692237\n"
     ]
    }
   ],
   "source": [
    "kw_i = 5 # 第几个 testing_keywords\n",
    "steps = len(group_dict)\n",
    "num_hidden = group_max_len\n",
    "transition_probs = np.array(transfer_matrices, dtype=float) # np.random.rand(steps-1, num_hidden, num_hidden)\n",
    "emission_probs = np.full((num_hidden, steps), -1000, dtype=float) # (num_hidden, steps)\n",
    "probs = prob_matrix[:, kw_i]\n",
    "for g_id in range(len(group_dict)):\n",
    "    group = group_dict[g_id]\n",
    "    for ind, report_id in enumerate(group):\n",
    "        emission_probs[ind, g_id] = probs[report_id]\n",
    "\n",
    "seq, prob = viterbi(emission_probs, transition_probs)\n",
    "print(seq, prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 展示推荐序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轨迹数据挖掘 :\n",
      "7 2021-10-16 13:30-13:45 基于轨迹数据的城市GNSS异常区域探测与特征分析 12.869185447692871\n",
      "13 2021-10-16 15:00-15:15 基于轨迹大数据的游客行为研究：总结、局限与展望 8.901477813720703\n",
      "15 2021-10-16 15:30-15:40 基于GPS轨迹的西藏骑行游客时空行为分析 6.296000003814697\n",
      "16 2021-10-16 15:50-16:10 地理大数据挖掘的方法体系及主要进展 3.6421022415161133\n",
      "20 2021-10-16 16:55-17:10 面向可持续发展目标的人类数字足迹挖掘研究 15.030759811401367\n",
      "21 2021-10-16 17:10-17:18 耦合词嵌入模型和多层注意力机制的城市人群轨迹预测研究 4.371326923370361\n",
      "31 2021-10-17 9:10-9:20 基于船舶轨迹数据的全球港口原油贸易网络分析 9.467353820800781\n",
      "32 2021-10-17 9:28-9:36 基于OCEAN大五人格的私家车轨迹画像研究 3.4262635707855225\n",
      "35 2021-10-17 10:26-10:34 基于稀疏时空轨迹嵌入的在线支付欺诈用户识别 3.7918202877044678\n",
      "37 2021-10-17 10:58-11:06 基于OSM与低频轨迹的道路方向信息提取 4.64129114151001\n",
      "38 2021-10-17 11:06-11:14 基于出租车轨迹数据的居民区房价分析与预测 7.685324668884277\n",
      "39 2021-10-17 11:30-11:38 基于轨迹数据的城市交通信息转向级挖掘与预测 18.307912826538086\n"
     ]
    }
   ],
   "source": [
    "print(testing_keywords[kw_i], ':')\n",
    "for i_group, ind in enumerate(seq):\n",
    "    report_id = group_dict[i_group][ind]\n",
    "    selected_report = sorted_data[report_id]\n",
    "    title = selected_report['title']\n",
    "    date, time = selected_report['date'], selected_report['time']\n",
    "    emi_prob = prob_matrix[report_id, kw_i]\n",
    "    if emi_prob > 3:\n",
    "        print(i_group, date+' '+time , title, emi_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始代码\n",
    "def step(mu_prev: np.ndarray,\n",
    "         emission_probs: np.ndarray,\n",
    "         transition_probs: np.ndarray,\n",
    "         observed_state: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Runs one step of the Viterbi algorithm.\n",
    "    \n",
    "    Args:\n",
    "        mu_prev: probability distribution with shape (num_hidden),\n",
    "            the previous mu\n",
    "        emission_probs: the emission probability matrix (num_hidden,\n",
    "            num_observed)\n",
    "        transition_probs: the transition probability matrix, with\n",
    "            shape (num_hidden, num_hidden)\n",
    "        observed_state: the observed state at the current step\n",
    "    \n",
    "    Returns:\n",
    "        - the mu for the next step\n",
    "        - the maximizing previous state, before the current state,\n",
    "          as an int array with shape (num_hidden)\n",
    "    \"\"\"\n",
    "    \n",
    "    pre_max = mu_prev * transition_probs.T\n",
    "    max_prev_states = np.argmax(pre_max, axis=1)\n",
    "    max_vals = pre_max[np.arange(len(max_prev_states)), max_prev_states]\n",
    "    mu_new = max_vals * emission_probs[:, observed_state]\n",
    "    \n",
    "    return mu_new, max_prev_states\n",
    "\n",
    "\n",
    "def viterbi(emission_probs: np.ndarray,\n",
    "            transition_probs: np.ndarray,\n",
    "            start_probs: np.ndarray,\n",
    "            observed_states: List[int]) -> Tuple[List[int], float]:\n",
    "    \"\"\"Runs the Viterbi algorithm to get the most likely state sequence.\n",
    "    \n",
    "    Args:\n",
    "        emission_probs: the emission probability matrix (num_hidden,\n",
    "            num_observed)\n",
    "        transition_probs: the transition probability matrix, with\n",
    "            shape (num_hidden, num_hidden)\n",
    "        start_probs: the initial probabilies for each state, with shape\n",
    "            (num_hidden)\n",
    "        observed_states: the observed states at each step\n",
    "    \n",
    "    Returns:\n",
    "        - the most likely series of states\n",
    "        - the joint probability of that series of states and the observed\n",
    "    \"\"\"\n",
    "    \n",
    "    # Runs the forward pass, storing the most likely previous state.\n",
    "    mu = start_probs * emission_probs[:, observed_states[0]]\n",
    "    all_prev_states = []\n",
    "    for observed_state in observed_states[1:]:\n",
    "        mu, prevs = step(mu, emission_probs, transition_probs, observed_state)\n",
    "        all_prev_states.append(prevs)\n",
    "    \n",
    "    # Traces backwards to get the maximum likelihood sequence.\n",
    "    state = np.argmax(mu)\n",
    "    sequence_prob = mu[state]\n",
    "    state_sequence = [state]\n",
    "    for prev_states in all_prev_states[::-1]:\n",
    "        state = prev_states[state]\n",
    "        state_sequence.append(state)\n",
    "    \n",
    "    return state_sequence[::-1], sequence_prob"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3725f9b6c50a9b1fb43ec92b9baad151c68ab0d5bd398e882ebcf6dd7767f72c"
  },
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('forltp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
