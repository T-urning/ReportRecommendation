{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 报告数据标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481 {'date': '2021-10-16 星期六', 'hall': '黄龙水晶宫', 'host': '陆锋', 'topic': '09:10-10:40 | 特邀报告', 'time': '09:10-09:40', 'title': '全球位置服务网关键技术与研究进展', 'reporters': '龚健雅 院士', 'institutions': '武汉大学'} {'分会场六', '分会场十一', '分会场五', '分会场十二', '分会场十三', '分会场三', '分会场十', '分会场二', '分会场七', '分会场四', '分会场八', '分会场一', '分会场十四', '黄龙水晶宫', '分会场九'}\n",
      "{'分会场一': 0, '分会场七': 1, '分会场三': 2, '分会场九': 3, '分会场二': 4, '分会场五': 5, '分会场八': 6, '分会场六': 7, '分会场十': 8, '分会场十一': 9, '分会场十三': 10, '分会场十二': 11, '分会场十四': 12, '分会场四': 13, '黄龙水晶宫': 14}\n"
     ]
    }
   ],
   "source": [
    "data = json.load(open('data/conference/conference.json', encoding='utf-8', mode='r'))\n",
    "reports = []\n",
    "halls = set()\n",
    "for report in data:\n",
    "    title = report['title']\n",
    "    institutions = report['institutions']\n",
    "    if title and institutions:\n",
    "        reports.append(report)\n",
    "        halls.add(report['hall'])\n",
    "\n",
    "hall_2_id = {h:i for i, h in enumerate(sorted(halls))}\n",
    "id_2_hall = {i:h for h, i in hall_2_id.items()}\n",
    "print(len(reports), reports[0], halls)\n",
    "print(hall_2_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 报告时间与会场标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '2021-10-16 星期六', 'hall': '黄龙水晶宫', 'host': '陆锋', 'topic': '09:10-10:40 | 特邀报告', 'time': '09:10-09:40', 'title': '全球位置服务网关键技术与研究进展', 'reporters': '龚健雅 院士', 'institutions': '武汉大学', 'start_time': 119400, 'end_time': 121200, 'hall_id': 14}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "time_format = '%Y-%m-%d %H:%M'\n",
    "base_time = datetime(2021, 10, 15)\n",
    "new_data = []\n",
    "start_time_set = set()\n",
    "for report in reports:\n",
    "    date = report['date']\n",
    "    time = report['time']\n",
    "    hall = report['hall']\n",
    "    date = date.split(' ')[0]\n",
    "    start, end = time.split('-')\n",
    "    start_time = date + ' ' + start # datetime.strptime(date + ' ' + start, time_format)\n",
    "    end_time = date + ' ' + end\n",
    "    s_time = datetime.strptime(start_time, time_format) - base_time\n",
    "    e_time = datetime.strptime(end_time, time_format) -  base_time\n",
    "    hall_id = hall_2_id[hall]\n",
    "    report['start_time'] = int(s_time.total_seconds())\n",
    "    report['end_time'] = int(e_time.total_seconds())\n",
    "    report['hall_id'] = hall_id\n",
    "    start_time_set.add(start_time)\n",
    "    new_data.append(report)\n",
    "json.dump(new_data, open('data/conference/standard_conference_data.json', 'w', encoding='utf-8'), ensure_ascii=False)\n",
    "print(new_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 按时间段分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "min_delta = 600\n",
    "time_spans = []\n",
    "sorted_data = sorted(new_data, key=lambda x: x['start_time']) # 按开始时间排序\n",
    "t = sorted_data[0]['start_time']\n",
    "group = 0\n",
    "group_dict = dict()\n",
    "group_dict[group] = []\n",
    "for i, report in enumerate(sorted_data):\n",
    "    s_time = int(report['start_time'])\n",
    "    e_time = int(report['end_time'])\n",
    "    delta = s_time - t\n",
    "    if delta <= min_delta:\n",
    "        group_dict[group].append(i)\n",
    "    else:\n",
    "        group += 1\n",
    "        t = s_time\n",
    "        group_dict[group] = [i]\n",
    "    report['time_group'] = group\n",
    "print(group)\n",
    "json.dump(sorted_data, open(f'data/conference/grouped_conference_data_{min_delta}.json', 'w', encoding='utf-8'), ensure_ascii=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最长组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "group_max_len = max([len(g) for k, g in group_dict.items()])\n",
    "print(group_max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概率转移矩阵中参数的确定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 空间距离因素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. 10.  2. 10.  2. 10. 10. 10. 15. 15. 15. 15. 15.  2.  2.]\n",
      " [10.  1. 10.  3. 10.  3.  3.  3. 20. 20. 20. 20. 20. 10. 10.]\n",
      " [ 2. 10.  1. 10.  2. 10. 10. 10. 15. 15. 15. 15. 15.  2.  2.]\n",
      " [10.  3. 10.  1. 10.  3.  3.  3. 20. 20. 20. 20. 20. 10. 10.]\n",
      " [ 2. 10.  2. 10.  1. 10. 10. 10. 15. 15. 15. 15. 15.  2.  2.]\n",
      " [10.  3. 10.  3. 10.  1.  3.  3. 20. 20. 20. 20. 20. 10. 10.]\n",
      " [10.  3. 10.  3. 10.  3.  1.  3. 20. 20. 20. 20. 20. 10. 10.]\n",
      " [10.  3. 10.  3. 10.  3.  3.  1. 20. 20. 20. 20. 20. 10. 10.]\n",
      " [15. 20. 15. 20. 15. 20. 20. 20.  1.  3.  3.  3.  3. 15. 15.]\n",
      " [15. 20. 15. 20. 15. 20. 20. 20.  3.  1.  3.  3.  3. 15. 15.]\n",
      " [15. 20. 15. 20. 15. 20. 20. 20.  3.  3.  1.  3.  3. 15. 15.]\n",
      " [15. 20. 15. 20. 15. 20. 20. 20.  3.  3.  3.  1.  3. 15. 15.]\n",
      " [15. 20. 15. 20. 15. 20. 20. 20.  3.  3.  3.  3.  1. 15. 15.]\n",
      " [ 2. 10.  2. 10.  2. 10. 10. 10. 15. 15. 15. 15. 15.  1.  2.]\n",
      " [ 2. 10.  2. 10.  2. 10. 10. 10. 15. 15. 15. 15. 15.  2.  1.]]\n"
     ]
    }
   ],
   "source": [
    "area1 = {'分会场一', '分会场二', '分会场三', '分会场四', '黄龙水晶宫'}\n",
    "area2 = {'分会场五', '分会场六', '分会场七', '分会场八', '分会场九'}\n",
    "area3 = {'分会场十', '分会场十一', '分会场十二', '分会场十三', '分会场十四'}\n",
    "distance_dict = {\n",
    "    '11': 2, '22': 3, '33': 3,\n",
    "    '12': 10, '21': 10, '13': 15, '31':15,\n",
    "    '23': 20, '32': 20\n",
    "}\n",
    "distance_matrix = np.zeros((len(hall_2_id), len(hall_2_id)), dtype=float)\n",
    "hall_2_area = {h: 1 for h in area1}\n",
    "hall_2_area.update({h: 2 for h in area2})\n",
    "hall_2_area.update({h: 3 for h in area3})\n",
    "\n",
    "for i in range(len(hall_2_id)):\n",
    "    from_hall = id_2_hall[i]\n",
    "    from_area = hall_2_area[from_hall]\n",
    "    distance_matrix[i, i] = 1\n",
    "    for j in range(i):\n",
    "        to_hall = id_2_hall[j]\n",
    "        to_area = hall_2_area[to_hall]\n",
    "        dis = distance_dict[str(from_area)+str(to_area)]\n",
    "        distance_matrix[i, j] = distance_matrix[j, i] = dis\n",
    "print(distance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 时间间隔因素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(start_time_set)\n",
    "transfer_matrices = []\n",
    "for i in range(len(group_dict)-1):\n",
    "    transfer_mat = np.zeros((group_max_len, group_max_len), dtype=float)\n",
    "    from_group = group_dict[i]\n",
    "    to_group = group_dict[i+1]\n",
    "    for i, from_r in enumerate(from_group):\n",
    "        from_hall_id = sorted_data[from_r]['hall_id']\n",
    "        for j, to_r in enumerate(to_group):\n",
    "            to_hall_id = sorted_data[to_r]['hall_id']\n",
    "            distance = distance_matrix[from_hall_id, to_hall_id]\n",
    "            transfer_mat[i, j] = 1 / distance # 距离的倒数\n",
    "    transfer_matrices.append(transfer_mat)\n",
    "print(transfer_matrices[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 条件随机场"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "def step(mu_prev: np.ndarray,\n",
    "         emission_probs: np.ndarray,\n",
    "         transition_probs: np.ndarray,\n",
    "         observed_state: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Runs one step of the Viterbi algorithm.\n",
    "    \n",
    "    Args:\n",
    "        mu_prev: probability distribution with shape (num_hidden),\n",
    "            the previous mu\n",
    "        emission_probs: the emission probability matrix (num_hidden,\n",
    "            num_observed)\n",
    "        transition_probs: the transition probability matrix, with\n",
    "            shape (num_hidden, num_hidden)\n",
    "        observed_state: the observed state at the current step\n",
    "    \n",
    "    Returns:\n",
    "        - the mu for the next step\n",
    "        - the maximizing previous state, before the current state,\n",
    "          as an int array with shape (num_hidden)\n",
    "    \"\"\"\n",
    "    \n",
    "    pre_max = mu_prev * transition_probs.T\n",
    "    max_prev_states = np.argmax(pre_max, axis=1)\n",
    "    max_vals = pre_max[np.arange(len(max_prev_states)), max_prev_states]\n",
    "    mu_new = max_vals * emission_probs[:, observed_state]\n",
    "    \n",
    "    return mu_new, max_prev_states\n",
    "\n",
    "\n",
    "def viterbi(emission_probs: np.ndarray,\n",
    "            transition_probs: np.ndarray,\n",
    "            start_probs: np.ndarray,\n",
    "            observed_states: List[int]) -> Tuple[List[int], float]:\n",
    "    \"\"\"Runs the Viterbi algorithm to get the most likely state sequence.\n",
    "    \n",
    "    Args:\n",
    "        emission_probs: the emission probability matrix (num_hidden,\n",
    "            num_observed)\n",
    "        transition_probs: the transition probability matrix, with\n",
    "            shape (num_hidden, num_hidden)\n",
    "        start_probs: the initial probabilies for each state, with shape\n",
    "            (num_hidden)\n",
    "        observed_states: the observed states at each step\n",
    "    \n",
    "    Returns:\n",
    "        - the most likely series of states\n",
    "        - the joint probability of that series of states and the observed\n",
    "    \"\"\"\n",
    "    \n",
    "    # Runs the forward pass, storing the most likely previous state.\n",
    "    mu = start_probs * emission_probs[:, observed_states[0]]\n",
    "    all_prev_states = []\n",
    "    for observed_state in observed_states[1:]:\n",
    "        mu, prevs = step(mu, emission_probs, transition_probs, observed_state)\n",
    "        all_prev_states.append(prevs)\n",
    "    \n",
    "    # Traces backwards to get the maximum likelihood sequence.\n",
    "    state = np.argmax(mu)\n",
    "    sequence_prob = mu[state]\n",
    "    state_sequence = [state]\n",
    "    for prev_states in all_prev_states[::-1]:\n",
    "        state = prev_states[state]\n",
    "        state_sequence.append(state)\n",
    "    \n",
    "    return state_sequence[::-1], sequence_prob"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3725f9b6c50a9b1fb43ec92b9baad151c68ab0d5bd398e882ebcf6dd7767f72c"
  },
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('forltp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
